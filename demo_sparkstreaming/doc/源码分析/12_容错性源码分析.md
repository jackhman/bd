## executor端容错

 # 热备

   Receiver[T](val storageLevel: StorageLevel) -> store

      ReceiverSupervisorImpl.pushBytes -> pushAndReportBlock

          ReceivedBlockHandler.storeBlock  - trackerEndpoint.askWithRetry

              BlockManagerBasedBlockHandler.storeBlock

                 BlockManager.putBytes -> doPutBytes -> doPut ( if (level.replication > 1) ) -> replicate

  # 冷备

    WriteAheadLogBasedBlockHandler.storeBlock

       WriteAheadLog.write

    WriteAheadLog                 WriteAheadLogRecordHandle（文件句柄）
          |                                    |
    FileBasedWriteAheadLog        FileBasedWriteAheadLogSegment


    FileBasedWriteAheadLogRandomReader：随机读
    FileBasedWriteAheadLogReader：顺序读

## driver端容错

   # ReceivedBlockTracker容错：WAL 冷备 => 恢复ReceivedBlockTracker的成员

     ReceivedBlockTracker.addBlock/allocateBlocksToBatch/cleanupOldBatches -> writeToLog

   # DStream, JobGenerator 容错：Checkpoint 冷备 => 重启StreamingContext/记录未完成的batch

     JobSet生成之后： JobGenerator.generateJobs

     JobSet执行完成之后：JobGenerator.clearMetadata

       JobGenerator.processEvent

         JobGenerator.doCheckpoint()

## 故障恢复


  # StreamingContext重构

  StreamingContext.getOrCreate

     CheckpointReader.read

         Checkpoint.deserialize

     SparkContext.getOrCreate(恢复sc/conf/env)

     _cp.graph.restoreCheckpointData() (根据依赖关系还原DStream)


  # 处理未完成的batch

  StreamingContext.start

     JobScheduler.start

         JobGenerator.start -> restart

            jobScheduler.receiverTracker.allocateBlocksToBatch(time) // allocate received blocks to batch
            jobScheduler.submitJobSet(JobSet(time, graph.generateJobs(time)))

